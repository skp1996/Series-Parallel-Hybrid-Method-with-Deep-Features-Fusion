{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38be523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,Ridge, LinearRegression,HuberRegressor,SGDRegressor,TweedieRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor, AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor,VotingRegressor\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ae4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,LSTM, GRU,Bidirectional,TimeDistributed, ConvLSTM2D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.metrics import RootMeanSquaredError,mean_absolute_percentage_error\n",
    "from keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeccf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate time series into patterns\n",
    "def get_Patterns(TSeries, n_inputs,h):\n",
    "    X,y,z = pd.DataFrame(np.zeros((len(TSeries)-n_inputs-h+1,n_inputs))), pd.DataFrame(), pd.DataFrame()\n",
    "    for i in range(len(TSeries)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_inputs + h - 1\n",
    "        # check if we are beyond the time series\n",
    "        if end_ix > len(TSeries)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        for j in range(n_inputs):\n",
    "            X.loc[i,j]=TSeries.iloc[i+j,0]\n",
    "        i=i+n_inputs\n",
    "        y=y.append(TSeries.iloc[end_ix], ignore_index = True)\n",
    "        sinX=pd.DataFrame(np.sin(X))\n",
    "        cosX=pd.DataFrame(np.cos(X))\n",
    "        squareX=pd.DataFrame(np.power(X,2))\n",
    "        X1=np.hstack((X,sinX,cosX,squareX))\n",
    "    return np.array(X1),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9c68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalData should be a Column Vectored DataFrame\n",
    "def minmaxNorm(originalData, lenTrainValidation):\n",
    "    max2norm=max(originalData.iloc[0:lenTrainValidation,0])\n",
    "    min2norm=min(originalData.iloc[0:lenTrainValidation,0])\n",
    "    lenOriginal=len(originalData)\n",
    "    normalizedData=np.zeros(lenOriginal)   \n",
    "    normalizedData = []\n",
    "    for i in range (lenOriginal):\n",
    "        normalizedData.append((originalData.iloc[i]-min2norm)/(max2norm-min2norm))    \n",
    "    return pd.DataFrame(normalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c481549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalData and forecastedData should be Column Vectored DataFrames\n",
    "def minmaxDeNorm( originalData, forecastedData, lenTrainValidation):\n",
    "    max2norm=max(originalData.iloc[0:lenTrainValidation,0])\n",
    "    min2norm=min(originalData.iloc[0:lenTrainValidation,0])\n",
    "    lenOriginal=len(originalData)\n",
    "    denormalizedData=[]    \n",
    "    for i in range (lenOriginal):\n",
    "        denormalizedData.append((forecastedData.iloc[i]*(max2norm-min2norm))+min2norm)  \n",
    "    return pd.DataFrame(denormalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5142a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findRMSE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    trainRMSE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainRMSE=trainRMSE+np.power((forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]),2) \n",
    "    trainRMSE=np.sqrt(trainRMSE/lenTrainValidation)\n",
    "\n",
    "    testRMSE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testRMSE=testRMSE+np.power((forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]),2)\n",
    "    testRMSE=np.sqrt(testRMSE/lenTest)\n",
    "    return trainRMSE, testRMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9147158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findSMAPE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    trainSMAPE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainSMAPE=trainSMAPE+(np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])/((np.abs(forecasted_value.iloc[i,0])+np.abs(Timeseries_Data.iloc[i,0]))/2))\n",
    "    \n",
    "    trainSMAPE=(trainSMAPE/(lenTrainValidation))*100;\n",
    "\n",
    "    testSMAPE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testSMAPE=testSMAPE+(np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])/((np.abs(forecasted_value.iloc[i,0])+np.abs(Timeseries_Data.iloc[i,0]))/2))\n",
    "    \n",
    "    testSMAPE=(testSMAPE/lenTest)*100;\n",
    "    return trainSMAPE, testSMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f22d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findMAE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    trainMAE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainMAE=trainMAE+np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]) \n",
    "    trainMAE=(trainMAE/(lenTrainValidation));\n",
    "\n",
    "    testMAE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testMAE=testMAE+np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])\n",
    "    testMAE=(testMAE/lenTest);\n",
    "    return trainMAE, testMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db78d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findMASE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    trainMASE=0;\n",
    "    T1=Timeseries_Data.iloc[0:lenTrainValidation,0]\n",
    "    T2=T1.diff()\n",
    "    T2=T2.drop(0)\n",
    "    T2=np.abs(T2)\n",
    "    M=np.mean(T2)\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainMASE=trainMASE+(np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])/M) \n",
    "\n",
    "    trainMASE=(trainMASE/(lenTrainValidation))\n",
    "\n",
    "    testMASE=0\n",
    "    T1=Timeseries_Data.iloc[lenTrainValidation:l,0]\n",
    "    T2=T1.diff()\n",
    "    T2=T2.drop(lenTrainValidation)\n",
    "    T2=np.abs(T2)\n",
    "    M=np.mean(T2)\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testMASE=testMASE+(np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])/M)\n",
    "    testMASE=(testMASE/lenTest)\n",
    "    return trainMASE,testMASE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1068a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Activation_Function(no):\n",
    "    if no==0:\n",
    "        return \"relu\"\n",
    "    elif no==1:\n",
    "        return \"sigmoid\"\n",
    "    elif no==2:\n",
    "        return \"tanh\"\n",
    "    elif no==3:\n",
    "        return \"selu\"\n",
    "    elif no==4:\n",
    "        return \"exponential\"\n",
    "    else:\n",
    "        return \"elu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c86bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_initializer(no):\n",
    "    if no==0:\n",
    "        return \"glorot_uniform\"\n",
    "    elif no==1:\n",
    "        return \"glorot_normal\"\n",
    "    elif no==2:\n",
    "        return \"he_uniform\"\n",
    "    else:\n",
    "        return \"he_normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fde0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Features_LSTM(x,y,lenValid,lenTest):\n",
    "    NOP=len(y)\n",
    "    n_features=1\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    LagLength=x.shape[1]\n",
    "    xTrain=x[0:lenTrain,:]\n",
    "    xValid=x[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y[0:lenTrain,0]\n",
    "    yValid=y[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y[(lenTrain+lenValid):NOP,0]\n",
    "    model1 = Sequential()\n",
    "    model1.add(LSTM(256, activation='tanh', input_shape=(LagLength,n_features),kernel_initializer=\"he_normal\",name=\"layer1\"))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(16, activation='relu',kernel_initializer=\"he_normal\",name=\"layer2\"))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "    checkpoint_filepath = './'\n",
    "    cp1=ModelCheckpoint(checkpoint_filepath,save_best_only='True')\n",
    "    model1.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.0001),metrics=[RootMeanSquaredError()])\n",
    "    # fit\n",
    "    model1.fit(xTrain, yTrain,validation_data=(xValid,yValid), epochs=100, verbose=1,batch_size=16)\n",
    "    yhatNorm=model1.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    feature_extractor = Model(inputs=model1.inputs, outputs=model1.get_layer(name=\"layer2\").output)\n",
    "    features = pd.DataFrame(feature_extractor.predict(x))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c48807ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Features_CNN(x,y,lenValid,lenTest):\n",
    "    NOP=len(y)\n",
    "    n_features=1\n",
    "    LagLength=x.shape[1]\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    xTrain=x[0:lenTrain,:]\n",
    "    xValid=x[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y[0:lenTrain,0]\n",
    "    yValid=y[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y[(lenTrain+lenValid):NOP,0]\n",
    "    x = x.reshape((x.shape[0], x.shape[1], n_features))\n",
    "    model1 = Sequential()\n",
    "    model1.add(Conv1D(filters=256, kernel_size=2, activation='tanh', input_shape=(LagLength,n_features),kernel_initializer=\"he_normal\",name=\"layer1\"))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(16, activation='relu',kernel_initializer=\"he_normal\",name=\"layer2\"))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "    checkpoint_filepath = './'\n",
    "    cp1=ModelCheckpoint(checkpoint_filepath,save_best_only='True')\n",
    "    model1.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.0001),metrics=[RootMeanSquaredError()])\n",
    "    # fit\n",
    "    model1.fit(xTrain, yTrain,validation_data=(xValid,yValid), epochs=100, verbose=1,batch_size=16)\n",
    "    yhatNorm=model1.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    feature_extractor = Model(inputs=model1.inputs, outputs=model1.get_layer(name=\"layer2\").output)\n",
    "    features = pd.DataFrame(feature_extractor.predict(x).reshape(x.shape[0],16))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294ac461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Features_ConvLSTM(x,y,lenValid,lenTest):\n",
    "    NOP=len(y)\n",
    "    n_features=1\n",
    "    n_seq=1\n",
    "    LagLength=x.shape[1]\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    xTrain=x[0:lenTrain,:]\n",
    "    xValid=x[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y[0:lenTrain,0]\n",
    "    yValid=y[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y[(lenTrain+lenValid):NOP,0]\n",
    "    xTrain=xTrain.reshape((xTrain.shape[0], n_seq, 1, LagLength, n_features))\n",
    "    xValid=xValid.reshape((xValid.shape[0], n_seq, 1, LagLength, n_features))\n",
    "    xTest=xTest.reshape((xTest.shape[0], n_seq, 1, LagLength, n_features))\n",
    "    x=x.reshape((x.shape[0], n_seq, 1, LagLength, n_features))\n",
    "    model1 = Sequential()\n",
    "    model1.add(ConvLSTM2D(filters=256, kernel_size=(1,2), activation='tanh',kernel_initializer=\"he_normal\" , input_shape=(n_seq,1, LagLength, n_features),name=\"layer1\"))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(16, activation='relu',kernel_initializer=\"he_normal\",name=\"layer2\"))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "    checkpoint_filepath = './'\n",
    "    cp1=ModelCheckpoint(checkpoint_filepath,save_best_only='True')\n",
    "    model1.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.0001),metrics=[RootMeanSquaredError()])\n",
    "    # fit\n",
    "    model1.fit(xTrain, yTrain,validation_data=(xValid,yValid), epochs=100, verbose=1,batch_size=16)\n",
    "    yhatNorm=model1.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    feature_extractor = Model(inputs=model1.inputs, outputs=model1.get_layer(name=\"layer2\").output)\n",
    "    features = pd.DataFrame(feature_extractor.predict(x).reshape(x.shape[0],16))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00abc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Features_BiLSTM(x,y,lenValid,lenTest):\n",
    "    NOP=len(y)\n",
    "    n_features=1\n",
    "    LagLength=x.shape[1]\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    xTrain=x[0:lenTrain,:]\n",
    "    xValid=x[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y[0:lenTrain,0]\n",
    "    yValid=y[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y[(lenTrain+lenValid):NOP,0]\n",
    "    model1 = Sequential()\n",
    "    model1.add(Bidirectional(LSTM(256, activation='tanh',kernel_initializer=\"he_normal\"),input_shape=(LagLength,n_features),name=\"layer1\"))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(16, activation='relu',kernel_initializer=\"he_normal\",name=\"layer2\"))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "    checkpoint_filepath = './'\n",
    "    cp1=ModelCheckpoint(checkpoint_filepath,save_best_only='True')\n",
    "    model1.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.0001),metrics=[RootMeanSquaredError()])\n",
    "    # fit\n",
    "    model1.fit(xTrain, yTrain,validation_data=(xValid,yValid), epochs=100, verbose=1,batch_size=16)\n",
    "    yhatNorm=model1.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    feature_extractor = Model(inputs=model1.inputs, outputs=model1.get_layer(name=\"layer2\").output)\n",
    "    features = pd.DataFrame(feature_extractor.predict(x))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b58d45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Features_GRU(x,y,lenValid,lenTest):\n",
    "    NOP=len(y)\n",
    "    n_features=1\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    LagLength=x.shape[1]\n",
    "    xTrain=x[0:lenTrain,:]\n",
    "    xValid=x[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y[0:lenTrain,0]\n",
    "    yValid=y[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y[(lenTrain+lenValid):NOP,0]\n",
    "    model1 = Sequential()\n",
    "    model1.add(GRU(256, activation='tanh', input_shape=(LagLength,n_features),kernel_initializer=\"he_normal\",name=\"layer1\"))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(16, activation='relu',kernel_initializer=\"he_normal\"))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "    checkpoint_filepath = './'\n",
    "    cp1=ModelCheckpoint(checkpoint_filepath,save_best_only='True')\n",
    "    model1.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.01),metrics=[RootMeanSquaredError()])\n",
    "    # fit\n",
    "    model1.fit(xTrain, yTrain,validation_data=(xValid,yValid), epochs=100, verbose=1,batch_size=16)\n",
    "    yhatNorm=model1.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    feature_extractor = Model(inputs=model1.inputs, outputs=model1.get_layer(name=\"layer1\").output)\n",
    "    features = pd.DataFrame(feature_extractor.predict(x))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1af1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Fitness(x,y,lenValid,lenTest,model):\n",
    "    NOP=y.shape[0]\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    xTrain=x[0:(lenTrain+lenValid),:]\n",
    "    xValid=x[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y[0:(lenTrain+lenValid),0]\n",
    "    yValid=y[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y[(lenTrain+lenValid):NOP,0]\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yhatNorm=model.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    return pd.DataFrame(yhatNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af9a65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findUOD(TimeSeries):\n",
    "    Dmin=np.min(TimeSeries)\n",
    "    Dmax=np.max(TimeSeries)\n",
    "    D1=0.2*(Dmax-Dmin)\n",
    "    D2=0.2*(Dmax-Dmin)\n",
    "    U=pd.DataFrame(np.zeros((1,2)))\n",
    "    U.iloc[0,0]=Dmin-D1\n",
    "    U.iloc[0,1]=Dmax+D2\n",
    "    return pd.DataFrame(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5e6a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 1.4327e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0012 - root_mean_squared_error: 0.0345 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0451\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0013 - root_mean_squared_error: 0.0361 - val_loss: 2.6203e-04 - val_root_mean_squared_error: 0.0162\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0013 - root_mean_squared_error: 0.0359 - val_loss: 2.5056e-04 - val_root_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 1.2689e-04 - val_root_mean_squared_error: 0.0113\n",
      "Epoch 6/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0012 - root_mean_squared_error: 0.0351 - val_loss: 5.9554e-04 - val_root_mean_squared_error: 0.0244\n",
      "Epoch 7/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0011 - root_mean_squared_error: 0.0339 - val_loss: 1.1874e-04 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 8/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0012 - root_mean_squared_error: 0.0341 - val_loss: 6.9128e-04 - val_root_mean_squared_error: 0.0263\n",
      "Epoch 9/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0012 - root_mean_squared_error: 0.0343 - val_loss: 7.2115e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 10/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0609 - root_mean_squared_error: 0.2468 - val_loss: 0.2035 - val_root_mean_squared_error: 0.4511\n",
      "Epoch 11/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.1251 - root_mean_squared_error: 0.3537 - val_loss: 0.0699 - val_root_mean_squared_error: 0.2643\n",
      "Epoch 12/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 13/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0407\n",
      "Epoch 14/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 0.0011 - root_mean_squared_error: 0.0324 - val_loss: 7.3756e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 15/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6105e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6096e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 16/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6038e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6056e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 17/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6047e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6100e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 18/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6053e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6911e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 19/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6053e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6175e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 20/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6063e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6310e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 21/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6056e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6065e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 22/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6046e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6418e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 23/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6052e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6098e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 24/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6049e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6058e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 25/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6058e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6240e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 26/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6050e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6069e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 27/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6038e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6057e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 28/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6053e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6071e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 29/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6051e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6444e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 30/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6048e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6225e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 31/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6055e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6479e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 32/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6054e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6077e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 33/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6052e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6118e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 34/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6052e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6227e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 35/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6051e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6060e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 36/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6049e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6055e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 37/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6060e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6837e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 38/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6058e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6327e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 39/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6057e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6125e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 40/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6053e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6054e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 41/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6053e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6290e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 42/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6056e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6242e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 43/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6051e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6747e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 44/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6033e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.7040e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 45/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6056e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6441e-05 - val_root_mean_squared_error: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6055e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.7112e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6055e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6445e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 48/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6042e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6086e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 49/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6054e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6087e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 50/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6031e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.8194e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 51/100\n",
      "1806/1806 [==============================] - 10s 6ms/step - loss: 6.6045e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6151e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 52/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6057e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6087e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 53/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6058e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6202e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 54/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6062e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6076e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 55/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6056e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6066e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 56/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6030e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6719e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 57/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6057e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6246e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 58/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6054e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6624e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 59/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6035e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6085e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 60/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6056e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6114e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 61/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6047e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6085e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 62/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6057e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6276e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 63/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6057e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.7249e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 64/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6060e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.7452e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 65/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6061e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6105e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 66/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6047e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6181e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 67/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6032e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.7481e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 68/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6065e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6110e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 69/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6055e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6327e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 70/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6047e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6631e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 71/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6048e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.8154e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 72/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6046e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6602e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 73/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6057e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6127e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 74/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6064e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6147e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 75/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6065e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6053e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 76/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6034e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6377e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 77/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6055e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6053e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 78/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6055e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6074e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 79/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6063e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6341e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 80/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6054e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6867e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 81/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6049e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6127e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 82/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6050e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6224e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 83/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6038e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6103e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 84/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6054e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6055e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 85/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6054e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6729e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 86/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6071e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6239e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 87/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6046e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6649e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 88/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6049e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6071e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 89/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6040e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6989e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6066e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6313e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 91/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6035e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6053e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 92/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6051e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6070e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 93/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6051e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6344e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 94/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6059e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6420e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 95/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6047e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6311e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 96/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6063e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6153e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 97/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6046e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6215e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 98/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6053e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6321e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 99/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6059e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6060e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 100/100\n",
      "1806/1806 [==============================] - 10s 5ms/step - loss: 6.6063e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6138e-05 - val_root_mean_squared_error: 0.0081\n",
      "1506/1506 [==============================] - 4s 3ms/step\n",
      "1506/1506 [==============================] - 4s 3ms/step\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 92s 50ms/step - loss: 0.0014 - root_mean_squared_error: 0.0374 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 0.0012 - root_mean_squared_error: 0.0340 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 7.8668e-04 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 4.3596e-04 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 5/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 0.0011 - root_mean_squared_error: 0.0325 - val_loss: 3.2882e-04 - val_root_mean_squared_error: 0.0181\n",
      "Epoch 6/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 4.8257e-04 - val_root_mean_squared_error: 0.0220\n",
      "Epoch 7/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0322\n",
      "Epoch 8/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 9.9490e-04 - root_mean_squared_error: 0.0315 - val_loss: 9.2224e-05 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 9/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 7.1974e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 10/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 0.0010 - root_mean_squared_error: 0.0316 - val_loss: 6.8721e-04 - val_root_mean_squared_error: 0.0262\n",
      "Epoch 11/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 9.6603e-04 - root_mean_squared_error: 0.0311 - val_loss: 1.6631e-04 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 12/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 9.4789e-04 - root_mean_squared_error: 0.0308 - val_loss: 6.8143e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 13/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 9.2341e-04 - root_mean_squared_error: 0.0304 - val_loss: 2.9094e-04 - val_root_mean_squared_error: 0.0171\n",
      "Epoch 14/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 9.3036e-04 - root_mean_squared_error: 0.0305 - val_loss: 1.0946e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 15/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 9.0518e-04 - root_mean_squared_error: 0.0301 - val_loss: 6.6628e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 16/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 9.0177e-04 - root_mean_squared_error: 0.0300 - val_loss: 5.2947e-04 - val_root_mean_squared_error: 0.0230\n",
      "Epoch 17/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 8.9014e-04 - root_mean_squared_error: 0.0298 - val_loss: 1.3451e-04 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 18/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 8.9877e-04 - root_mean_squared_error: 0.0300 - val_loss: 1.0936e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 19/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 8.6735e-04 - root_mean_squared_error: 0.0295 - val_loss: 7.9438e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 20/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 8.6455e-04 - root_mean_squared_error: 0.0294 - val_loss: 6.8356e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 21/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 8.4221e-04 - root_mean_squared_error: 0.0290 - val_loss: 2.2398e-04 - val_root_mean_squared_error: 0.0150\n",
      "Epoch 22/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 8.2340e-04 - root_mean_squared_error: 0.0287 - val_loss: 2.9740e-04 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 23/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 8.4071e-04 - root_mean_squared_error: 0.0290 - val_loss: 5.2009e-04 - val_root_mean_squared_error: 0.0228\n",
      "Epoch 24/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 8.2879e-04 - root_mean_squared_error: 0.0288 - val_loss: 3.4213e-04 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 25/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 8.5186e-04 - root_mean_squared_error: 0.0292 - val_loss: 1.2555e-04 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 26/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 8.1537e-04 - root_mean_squared_error: 0.0286 - val_loss: 1.3263e-04 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 27/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 8.0641e-04 - root_mean_squared_error: 0.0284 - val_loss: 7.6975e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 28/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.8711e-04 - root_mean_squared_error: 0.0281 - val_loss: 6.7394e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 29/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.9873e-04 - root_mean_squared_error: 0.0283 - val_loss: 6.2843e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 30/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 8.0429e-04 - root_mean_squared_error: 0.0284 - val_loss: 3.3150e-04 - val_root_mean_squared_error: 0.0182\n",
      "Epoch 31/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 7.8992e-04 - root_mean_squared_error: 0.0281 - val_loss: 6.2339e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 32/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 7.7849e-04 - root_mean_squared_error: 0.0279 - val_loss: 7.9909e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 33/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.7960e-04 - root_mean_squared_error: 0.0279 - val_loss: 6.4926e-05 - val_root_mean_squared_error: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 7.5798e-04 - root_mean_squared_error: 0.0275 - val_loss: 1.1723e-04 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 35/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.7303e-04 - root_mean_squared_error: 0.0278 - val_loss: 5.8336e-05 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 36/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.5490e-04 - root_mean_squared_error: 0.0275 - val_loss: 1.2037e-04 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 37/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.3927e-04 - root_mean_squared_error: 0.0272 - val_loss: 5.4914e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 38/100\n",
      "1806/1806 [==============================] - 105s 58ms/step - loss: 7.5720e-04 - root_mean_squared_error: 0.0275 - val_loss: 2.0399e-04 - val_root_mean_squared_error: 0.0143\n",
      "Epoch 39/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.5069e-04 - root_mean_squared_error: 0.0274 - val_loss: 1.2449e-04 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 40/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.4687e-04 - root_mean_squared_error: 0.0273 - val_loss: 3.6871e-04 - val_root_mean_squared_error: 0.0192\n",
      "Epoch 41/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.5270e-04 - root_mean_squared_error: 0.0274 - val_loss: 1.2353e-04 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 42/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.4864e-04 - root_mean_squared_error: 0.0274 - val_loss: 1.1428e-04 - val_root_mean_squared_error: 0.0107\n",
      "Epoch 43/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.4057e-04 - root_mean_squared_error: 0.0272 - val_loss: 5.8128e-05 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 44/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.2551e-04 - root_mean_squared_error: 0.0269 - val_loss: 5.8200e-04 - val_root_mean_squared_error: 0.0241\n",
      "Epoch 45/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.3145e-04 - root_mean_squared_error: 0.0270 - val_loss: 1.6707e-04 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 46/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.2986e-04 - root_mean_squared_error: 0.0270 - val_loss: 9.0600e-05 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 47/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.2824e-04 - root_mean_squared_error: 0.0270 - val_loss: 3.0571e-04 - val_root_mean_squared_error: 0.0175\n",
      "Epoch 48/100\n",
      "1806/1806 [==============================] - 106s 58ms/step - loss: 7.3245e-04 - root_mean_squared_error: 0.0271 - val_loss: 5.6315e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 49/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.2076e-04 - root_mean_squared_error: 0.0268 - val_loss: 2.1822e-04 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 50/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.1940e-04 - root_mean_squared_error: 0.0268 - val_loss: 6.1002e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 51/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.2721e-04 - root_mean_squared_error: 0.0270 - val_loss: 5.6898e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 52/100\n",
      "1806/1806 [==============================] - 106s 59ms/step - loss: 7.1214e-04 - root_mean_squared_error: 0.0267 - val_loss: 2.6242e-04 - val_root_mean_squared_error: 0.0162\n",
      "Epoch 53/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.2698e-04 - root_mean_squared_error: 0.0270 - val_loss: 4.1975e-04 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 54/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 7.1091e-04 - root_mean_squared_error: 0.0267 - val_loss: 1.1269e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 55/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 7.0978e-04 - root_mean_squared_error: 0.0266 - val_loss: 1.5032e-04 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 56/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.3230e-04 - root_mean_squared_error: 0.0271 - val_loss: 7.3366e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 57/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.0582e-04 - root_mean_squared_error: 0.0266 - val_loss: 8.5361e-05 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 58/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.1056e-04 - root_mean_squared_error: 0.0267 - val_loss: 7.5320e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 59/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.9500e-04 - root_mean_squared_error: 0.0264 - val_loss: 6.0834e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 60/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.0798e-04 - root_mean_squared_error: 0.0266 - val_loss: 7.3253e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 61/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.0037e-04 - root_mean_squared_error: 0.0265 - val_loss: 1.2647e-04 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 62/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.9341e-04 - root_mean_squared_error: 0.0263 - val_loss: 1.8892e-04 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 63/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 7.0909e-04 - root_mean_squared_error: 0.0266 - val_loss: 1.1334e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 64/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 7.0278e-04 - root_mean_squared_error: 0.0265 - val_loss: 5.5925e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 65/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.8913e-04 - root_mean_squared_error: 0.0263 - val_loss: 6.7975e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 66/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.8527e-04 - root_mean_squared_error: 0.0262 - val_loss: 8.2859e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 67/100\n",
      "1806/1806 [==============================] - 107s 60ms/step - loss: 6.9145e-04 - root_mean_squared_error: 0.0263 - val_loss: 8.1026e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 68/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.8461e-04 - root_mean_squared_error: 0.0262 - val_loss: 6.9285e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 69/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.9249e-04 - root_mean_squared_error: 0.0263 - val_loss: 7.8798e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 70/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.8254e-04 - root_mean_squared_error: 0.0261 - val_loss: 1.0068e-04 - val_root_mean_squared_error: 0.0100\n",
      "Epoch 71/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.7619e-04 - root_mean_squared_error: 0.0260 - val_loss: 6.5190e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 72/100\n",
      "1806/1806 [==============================] - 107s 60ms/step - loss: 6.8737e-04 - root_mean_squared_error: 0.0262 - val_loss: 5.1696e-05 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 73/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.8888e-04 - root_mean_squared_error: 0.0262 - val_loss: 9.9304e-05 - val_root_mean_squared_error: 0.0100\n",
      "Epoch 74/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.8115e-04 - root_mean_squared_error: 0.0261 - val_loss: 6.3214e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 75/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.7787e-04 - root_mean_squared_error: 0.0260 - val_loss: 1.0121e-04 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 76/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.7955e-04 - root_mean_squared_error: 0.0261 - val_loss: 1.3198e-04 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 77/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.7632e-04 - root_mean_squared_error: 0.0260 - val_loss: 1.1945e-04 - val_root_mean_squared_error: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.8506e-04 - root_mean_squared_error: 0.0262 - val_loss: 1.5662e-04 - val_root_mean_squared_error: 0.0125\n",
      "Epoch 79/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.7965e-04 - root_mean_squared_error: 0.0261 - val_loss: 6.2839e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 80/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.6823e-04 - root_mean_squared_error: 0.0259 - val_loss: 1.2344e-04 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 81/100\n",
      "1806/1806 [==============================] - 107s 60ms/step - loss: 6.7921e-04 - root_mean_squared_error: 0.0261 - val_loss: 1.1343e-04 - val_root_mean_squared_error: 0.0107\n",
      "Epoch 82/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.7667e-04 - root_mean_squared_error: 0.0260 - val_loss: 6.7139e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 83/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.7041e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.4791e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 84/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.7222e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.2600e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 85/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.7293e-04 - root_mean_squared_error: 0.0259 - val_loss: 5.3436e-05 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 86/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.7410e-04 - root_mean_squared_error: 0.0260 - val_loss: 9.8818e-05 - val_root_mean_squared_error: 0.0099\n",
      "Epoch 87/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6703e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.0470e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 88/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6772e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.1116e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 89/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.7177e-04 - root_mean_squared_error: 0.0259 - val_loss: 8.7254e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 90/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.7070e-04 - root_mean_squared_error: 0.0259 - val_loss: 1.4563e-04 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 91/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6296e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.0660e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 92/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6181e-04 - root_mean_squared_error: 0.0257 - val_loss: 7.9283e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 93/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6308e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.4557e-04 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 94/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6624e-04 - root_mean_squared_error: 0.0258 - val_loss: 9.0812e-05 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 95/100\n",
      "1806/1806 [==============================] - 107s 59ms/step - loss: 6.6956e-04 - root_mean_squared_error: 0.0259 - val_loss: 1.3238e-04 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 96/100\n",
      "1806/1806 [==============================] - 107s 60ms/step - loss: 6.5659e-04 - root_mean_squared_error: 0.0256 - val_loss: 5.0887e-05 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 97/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6786e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.0649e-04 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 98/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6015e-04 - root_mean_squared_error: 0.0257 - val_loss: 7.6831e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 99/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6019e-04 - root_mean_squared_error: 0.0257 - val_loss: 5.2863e-05 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 100/100\n",
      "1806/1806 [==============================] - 108s 60ms/step - loss: 6.6621e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.2427e-04 - val_root_mean_squared_error: 0.0111\n",
      "1506/1506 [==============================] - 48s 31ms/step\n",
      "1506/1506 [==============================] - 48s 32ms/step\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 245s 134ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 3.6940e-04 - val_root_mean_squared_error: 0.0192\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 236s 131ms/step - loss: 8.8767e-04 - root_mean_squared_error: 0.0298 - val_loss: 1.0922e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 245s 135ms/step - loss: 8.7340e-04 - root_mean_squared_error: 0.0296 - val_loss: 1.2319e-04 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 8.6913e-04 - root_mean_squared_error: 0.0295 - val_loss: 1.1184e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 5/100\n",
      "1806/1806 [==============================] - 232s 128ms/step - loss: 8.3620e-04 - root_mean_squared_error: 0.0289 - val_loss: 1.2893e-04 - val_root_mean_squared_error: 0.0114\n",
      "Epoch 6/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 8.2979e-04 - root_mean_squared_error: 0.0288 - val_loss: 1.9864e-04 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 7/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 8.1344e-04 - root_mean_squared_error: 0.0285 - val_loss: 6.5741e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 8/100\n",
      "1806/1806 [==============================] - 233s 129ms/step - loss: 8.0528e-04 - root_mean_squared_error: 0.0284 - val_loss: 6.4240e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 9/100\n",
      "1806/1806 [==============================] - 235s 130ms/step - loss: 7.8632e-04 - root_mean_squared_error: 0.0280 - val_loss: 7.3604e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 10/100\n",
      "1806/1806 [==============================] - 230s 128ms/step - loss: 7.8939e-04 - root_mean_squared_error: 0.0281 - val_loss: 7.5364e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 11/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 7.8040e-04 - root_mean_squared_error: 0.0279 - val_loss: 1.1092e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 12/100\n",
      "1806/1806 [==============================] - 232s 129ms/step - loss: 7.6348e-04 - root_mean_squared_error: 0.0276 - val_loss: 7.1569e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 13/100\n",
      "1806/1806 [==============================] - 227s 126ms/step - loss: 7.5988e-04 - root_mean_squared_error: 0.0276 - val_loss: 6.4772e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 14/100\n",
      "1806/1806 [==============================] - 246s 136ms/step - loss: 7.5557e-04 - root_mean_squared_error: 0.0275 - val_loss: 1.5412e-04 - val_root_mean_squared_error: 0.0124\n",
      "Epoch 15/100\n",
      "1806/1806 [==============================] - 237s 131ms/step - loss: 7.5235e-04 - root_mean_squared_error: 0.0274 - val_loss: 6.9054e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 16/100\n",
      "1806/1806 [==============================] - 230s 128ms/step - loss: 7.6151e-04 - root_mean_squared_error: 0.0276 - val_loss: 3.6576e-04 - val_root_mean_squared_error: 0.0191\n",
      "Epoch 17/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 7.5194e-04 - root_mean_squared_error: 0.0274 - val_loss: 7.4648e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 18/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 7.4010e-04 - root_mean_squared_error: 0.0272 - val_loss: 8.2105e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 19/100\n",
      "1806/1806 [==============================] - 234s 130ms/step - loss: 7.4077e-04 - root_mean_squared_error: 0.0272 - val_loss: 7.6450e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 20/100\n",
      "1806/1806 [==============================] - 237s 131ms/step - loss: 7.3662e-04 - root_mean_squared_error: 0.0271 - val_loss: 3.2490e-04 - val_root_mean_squared_error: 0.0180\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806/1806 [==============================] - 235s 130ms/step - loss: 7.3266e-04 - root_mean_squared_error: 0.0271 - val_loss: 8.0711e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 22/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 7.3994e-04 - root_mean_squared_error: 0.0272 - val_loss: 3.3705e-04 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 23/100\n",
      "1806/1806 [==============================] - 247s 137ms/step - loss: 7.4824e-04 - root_mean_squared_error: 0.0274 - val_loss: 1.0674e-04 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 24/100\n",
      "1806/1806 [==============================] - 234s 130ms/step - loss: 7.3545e-04 - root_mean_squared_error: 0.0271 - val_loss: 7.7302e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 25/100\n",
      "1806/1806 [==============================] - 242s 134ms/step - loss: 7.2526e-04 - root_mean_squared_error: 0.0269 - val_loss: 6.6623e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 26/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 7.3137e-04 - root_mean_squared_error: 0.0270 - val_loss: 8.0368e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 27/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 7.2375e-04 - root_mean_squared_error: 0.0269 - val_loss: 8.5824e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 28/100\n",
      "1806/1806 [==============================] - 234s 129ms/step - loss: 7.1586e-04 - root_mean_squared_error: 0.0268 - val_loss: 6.9111e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 29/100\n",
      "1806/1806 [==============================] - 233s 129ms/step - loss: 7.2453e-04 - root_mean_squared_error: 0.0269 - val_loss: 8.8515e-05 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 30/100\n",
      "1806/1806 [==============================] - 237s 131ms/step - loss: 7.1322e-04 - root_mean_squared_error: 0.0267 - val_loss: 8.9686e-05 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 31/100\n",
      "1806/1806 [==============================] - 247s 137ms/step - loss: 7.1989e-04 - root_mean_squared_error: 0.0268 - val_loss: 7.0639e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 32/100\n",
      "1806/1806 [==============================] - 235s 130ms/step - loss: 7.1477e-04 - root_mean_squared_error: 0.0267 - val_loss: 1.0636e-04 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 33/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 7.1048e-04 - root_mean_squared_error: 0.0267 - val_loss: 1.3990e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 34/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 7.0770e-04 - root_mean_squared_error: 0.0266 - val_loss: 1.1582e-04 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 35/100\n",
      "1806/1806 [==============================] - 247s 137ms/step - loss: 7.0154e-04 - root_mean_squared_error: 0.0265 - val_loss: 3.7536e-04 - val_root_mean_squared_error: 0.0194\n",
      "Epoch 36/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 7.1389e-04 - root_mean_squared_error: 0.0267 - val_loss: 7.2182e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 37/100\n",
      "1806/1806 [==============================] - 247s 137ms/step - loss: 7.0237e-04 - root_mean_squared_error: 0.0265 - val_loss: 8.7791e-05 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 38/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 7.0650e-04 - root_mean_squared_error: 0.0266 - val_loss: 2.3274e-04 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/100\n",
      "1806/1806 [==============================] - 235s 130ms/step - loss: 7.0004e-04 - root_mean_squared_error: 0.0265 - val_loss: 2.7279e-04 - val_root_mean_squared_error: 0.0165\n",
      "Epoch 40/100\n",
      "1806/1806 [==============================] - 237s 131ms/step - loss: 7.0439e-04 - root_mean_squared_error: 0.0265 - val_loss: 1.5184e-04 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 41/100\n",
      "1806/1806 [==============================] - 240s 133ms/step - loss: 6.9938e-04 - root_mean_squared_error: 0.0264 - val_loss: 1.4298e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 42/100\n",
      "1806/1806 [==============================] - 237s 131ms/step - loss: 7.0881e-04 - root_mean_squared_error: 0.0266 - val_loss: 1.3819e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 43/100\n",
      "1806/1806 [==============================] - 245s 136ms/step - loss: 6.9510e-04 - root_mean_squared_error: 0.0264 - val_loss: 8.4538e-05 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 44/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.9954e-04 - root_mean_squared_error: 0.0264 - val_loss: 5.8292e-05 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 45/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.9659e-04 - root_mean_squared_error: 0.0264 - val_loss: 1.6827e-04 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 46/100\n",
      "1806/1806 [==============================] - 232s 128ms/step - loss: 6.9964e-04 - root_mean_squared_error: 0.0265 - val_loss: 6.2364e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 47/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.9280e-04 - root_mean_squared_error: 0.0263 - val_loss: 8.9865e-05 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 48/100\n",
      "1806/1806 [==============================] - 230s 127ms/step - loss: 6.9236e-04 - root_mean_squared_error: 0.0263 - val_loss: 8.2972e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 49/100\n",
      "1806/1806 [==============================] - 230s 128ms/step - loss: 7.0018e-04 - root_mean_squared_error: 0.0265 - val_loss: 6.0599e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 50/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.9385e-04 - root_mean_squared_error: 0.0263 - val_loss: 6.2480e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 51/100\n",
      "1806/1806 [==============================] - 232s 128ms/step - loss: 6.8866e-04 - root_mean_squared_error: 0.0262 - val_loss: 1.9432e-04 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 52/100\n",
      "1806/1806 [==============================] - 246s 136ms/step - loss: 6.9539e-04 - root_mean_squared_error: 0.0264 - val_loss: 8.6070e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 53/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 6.9148e-04 - root_mean_squared_error: 0.0263 - val_loss: 1.1300e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 54/100\n",
      "1806/1806 [==============================] - 245s 136ms/step - loss: 6.9542e-04 - root_mean_squared_error: 0.0264 - val_loss: 6.1786e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 55/100\n",
      "1806/1806 [==============================] - 236s 131ms/step - loss: 6.8656e-04 - root_mean_squared_error: 0.0262 - val_loss: 1.2617e-04 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 56/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.8744e-04 - root_mean_squared_error: 0.0262 - val_loss: 4.3505e-04 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 57/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 6.9509e-04 - root_mean_squared_error: 0.0264 - val_loss: 6.4199e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 58/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 6.8593e-04 - root_mean_squared_error: 0.0262 - val_loss: 6.5976e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 59/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.8757e-04 - root_mean_squared_error: 0.0262 - val_loss: 8.2677e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 60/100\n",
      "1806/1806 [==============================] - 237s 131ms/step - loss: 6.8481e-04 - root_mean_squared_error: 0.0262 - val_loss: 5.4537e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 61/100\n",
      "1806/1806 [==============================] - 233s 129ms/step - loss: 6.8705e-04 - root_mean_squared_error: 0.0262 - val_loss: 3.0794e-04 - val_root_mean_squared_error: 0.0175\n",
      "Epoch 62/100\n",
      "1806/1806 [==============================] - 235s 130ms/step - loss: 6.7931e-04 - root_mean_squared_error: 0.0261 - val_loss: 2.3039e-04 - val_root_mean_squared_error: 0.0152\n",
      "Epoch 63/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 6.8324e-04 - root_mean_squared_error: 0.0261 - val_loss: 6.3625e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 64/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 6.8001e-04 - root_mean_squared_error: 0.0261 - val_loss: 1.1987e-04 - val_root_mean_squared_error: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "1806/1806 [==============================] - 246s 136ms/step - loss: 6.8649e-04 - root_mean_squared_error: 0.0262 - val_loss: 6.1337e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 66/100\n",
      "1806/1806 [==============================] - 242s 134ms/step - loss: 6.7608e-04 - root_mean_squared_error: 0.0260 - val_loss: 1.8522e-04 - val_root_mean_squared_error: 0.0136\n",
      "Epoch 67/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 6.7809e-04 - root_mean_squared_error: 0.0260 - val_loss: 6.9261e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 68/100\n",
      "1806/1806 [==============================] - 241s 134ms/step - loss: 6.7961e-04 - root_mean_squared_error: 0.0261 - val_loss: 6.1016e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 69/100\n",
      "1806/1806 [==============================] - 236s 131ms/step - loss: 6.8087e-04 - root_mean_squared_error: 0.0261 - val_loss: 6.7887e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 70/100\n",
      "1806/1806 [==============================] - 236s 131ms/step - loss: 6.7858e-04 - root_mean_squared_error: 0.0260 - val_loss: 7.0698e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 71/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 6.7811e-04 - root_mean_squared_error: 0.0260 - val_loss: 8.8877e-05 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 72/100\n",
      "1806/1806 [==============================] - 226s 125ms/step - loss: 6.7507e-04 - root_mean_squared_error: 0.0260 - val_loss: 6.6213e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 73/100\n",
      "1806/1806 [==============================] - 245s 136ms/step - loss: 6.7746e-04 - root_mean_squared_error: 0.0260 - val_loss: 9.8527e-05 - val_root_mean_squared_error: 0.0099\n",
      "Epoch 74/100\n",
      "1806/1806 [==============================] - 245s 136ms/step - loss: 6.7505e-04 - root_mean_squared_error: 0.0260 - val_loss: 8.6198e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 75/100\n",
      "1806/1806 [==============================] - 227s 125ms/step - loss: 6.7679e-04 - root_mean_squared_error: 0.0260 - val_loss: 7.0308e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 76/100\n",
      "1806/1806 [==============================] - 239s 132ms/step - loss: 6.7277e-04 - root_mean_squared_error: 0.0259 - val_loss: 1.4662e-04 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 77/100\n",
      "1806/1806 [==============================] - 230s 127ms/step - loss: 6.7090e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.4860e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 78/100\n",
      "1806/1806 [==============================] - 236s 130ms/step - loss: 6.7091e-04 - root_mean_squared_error: 0.0259 - val_loss: 1.1590e-04 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 79/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 6.7245e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.7568e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 80/100\n",
      "1806/1806 [==============================] - 227s 125ms/step - loss: 6.6973e-04 - root_mean_squared_error: 0.0259 - val_loss: 1.9131e-04 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 81/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.7240e-04 - root_mean_squared_error: 0.0259 - val_loss: 5.1968e-05 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 82/100\n",
      "1806/1806 [==============================] - 225s 125ms/step - loss: 6.6907e-04 - root_mean_squared_error: 0.0259 - val_loss: 5.7720e-05 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 83/100\n",
      "1806/1806 [==============================] - 225s 125ms/step - loss: 6.6944e-04 - root_mean_squared_error: 0.0259 - val_loss: 8.3183e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 84/100\n",
      "1806/1806 [==============================] - 225s 125ms/step - loss: 6.7131e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.0119e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 85/100\n",
      "1806/1806 [==============================] - 225s 125ms/step - loss: 6.6930e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.7865e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 86/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 6.7096e-04 - root_mean_squared_error: 0.0259 - val_loss: 7.7714e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 87/100\n",
      "1806/1806 [==============================] - 227s 126ms/step - loss: 6.6516e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.3759e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 88/100\n",
      "1806/1806 [==============================] - 231s 128ms/step - loss: 6.7307e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.3357e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 89/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 6.7010e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.3338e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 90/100\n",
      "1806/1806 [==============================] - 233s 129ms/step - loss: 6.6347e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.0855e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 91/100\n",
      "1806/1806 [==============================] - 227s 126ms/step - loss: 6.6660e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.2678e-04 - val_root_mean_squared_error: 0.0113\n",
      "Epoch 92/100\n",
      "1806/1806 [==============================] - 228s 126ms/step - loss: 6.6661e-04 - root_mean_squared_error: 0.0258 - val_loss: 5.8981e-05 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 93/100\n",
      "1806/1806 [==============================] - 245s 136ms/step - loss: 6.6562e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.1285e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 94/100\n",
      "1806/1806 [==============================] - 243s 134ms/step - loss: 6.6619e-04 - root_mean_squared_error: 0.0258 - val_loss: 8.9058e-05 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 95/100\n",
      "1806/1806 [==============================] - 245s 136ms/step - loss: 6.6712e-04 - root_mean_squared_error: 0.0258 - val_loss: 8.5985e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 96/100\n",
      "1806/1806 [==============================] - 229s 127ms/step - loss: 6.6393e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.0150e-04 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 97/100\n",
      "1806/1806 [==============================] - 233s 129ms/step - loss: 6.6320e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.0052e-05 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 98/100\n",
      "1806/1806 [==============================] - 227s 126ms/step - loss: 6.6084e-04 - root_mean_squared_error: 0.0257 - val_loss: 7.7190e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 99/100\n",
      "1806/1806 [==============================] - 233s 129ms/step - loss: 6.5759e-04 - root_mean_squared_error: 0.0256 - val_loss: 6.5615e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 100/100\n",
      "1806/1806 [==============================] - 238s 132ms/step - loss: 6.5721e-04 - root_mean_squared_error: 0.0256 - val_loss: 7.0427e-05 - val_root_mean_squared_error: 0.0084\n",
      "1506/1506 [==============================] - 199s 132ms/step\n",
      "1506/1506 [==============================] - 199s 132ms/step\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 153s 84ms/step - loss: 0.0013 - root_mean_squared_error: 0.0367 - val_loss: 3.5781e-04 - val_root_mean_squared_error: 0.0189\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 144s 80ms/step - loss: 7.2321e-04 - root_mean_squared_error: 0.0269 - val_loss: 1.4131e-04 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 144s 80ms/step - loss: 7.2130e-04 - root_mean_squared_error: 0.0269 - val_loss: 6.2601e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 144s 80ms/step - loss: 7.1219e-04 - root_mean_squared_error: 0.0267 - val_loss: 1.0302e-04 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 5/100\n",
      "1806/1806 [==============================] - 144s 80ms/step - loss: 7.0916e-04 - root_mean_squared_error: 0.0266 - val_loss: 9.6673e-05 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 6/100\n",
      "1806/1806 [==============================] - 144s 80ms/step - loss: 7.1080e-04 - root_mean_squared_error: 0.0267 - val_loss: 6.6382e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 7/100\n",
      "1806/1806 [==============================] - 141s 78ms/step - loss: 6.9453e-04 - root_mean_squared_error: 0.0264 - val_loss: 8.4496e-05 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.9456e-04 - root_mean_squared_error: 0.0264 - val_loss: 7.2739e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 9/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.9118e-04 - root_mean_squared_error: 0.0263 - val_loss: 7.0112e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 10/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.8729e-04 - root_mean_squared_error: 0.0262 - val_loss: 7.9188e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 11/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.8658e-04 - root_mean_squared_error: 0.0262 - val_loss: 1.2598e-04 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 12/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.8534e-04 - root_mean_squared_error: 0.0262 - val_loss: 7.2004e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 13/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7999e-04 - root_mean_squared_error: 0.0261 - val_loss: 7.8945e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 14/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.8202e-04 - root_mean_squared_error: 0.0261 - val_loss: 7.5324e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 15/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7874e-04 - root_mean_squared_error: 0.0261 - val_loss: 7.4836e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 16/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7835e-04 - root_mean_squared_error: 0.0260 - val_loss: 1.4007e-04 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 17/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7622e-04 - root_mean_squared_error: 0.0260 - val_loss: 1.0847e-04 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 18/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7710e-04 - root_mean_squared_error: 0.0260 - val_loss: 9.3483e-05 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 19/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7474e-04 - root_mean_squared_error: 0.0260 - val_loss: 7.2338e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 20/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7524e-04 - root_mean_squared_error: 0.0260 - val_loss: 7.2499e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 21/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7542e-04 - root_mean_squared_error: 0.0260 - val_loss: 8.4802e-05 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 22/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.7038e-04 - root_mean_squared_error: 0.0259 - val_loss: 9.4380e-05 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 23/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7175e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.7362e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 24/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7120e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.9739e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 25/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7028e-04 - root_mean_squared_error: 0.0259 - val_loss: 8.4155e-05 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 26/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6961e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.8075e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 27/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.7092e-04 - root_mean_squared_error: 0.0259 - val_loss: 8.4774e-05 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 28/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6952e-04 - root_mean_squared_error: 0.0259 - val_loss: 7.6953e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 29/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6936e-04 - root_mean_squared_error: 0.0259 - val_loss: 6.9193e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 30/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6769e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.3979e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 31/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.6894e-04 - root_mean_squared_error: 0.0259 - val_loss: 7.1276e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 32/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6840e-04 - root_mean_squared_error: 0.0259 - val_loss: 7.0070e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 33/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.6779e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.3670e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 34/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.6744e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.1550e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 35/100\n",
      "1806/1806 [==============================] - 135s 74ms/step - loss: 6.6547e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.8529e-05 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 36/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.6655e-04 - root_mean_squared_error: 0.0258 - val_loss: 1.2341e-04 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 37/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6630e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.1550e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 38/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6664e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.9686e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 39/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6560e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.2332e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 40/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6573e-04 - root_mean_squared_error: 0.0258 - val_loss: 7.3961e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 41/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6507e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.9063e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 42/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6760e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.7262e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 43/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6373e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.8736e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 44/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6480e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.9154e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 45/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.6475e-04 - root_mean_squared_error: 0.0258 - val_loss: 6.6609e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 46/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.6195e-04 - root_mean_squared_error: 0.0257 - val_loss: 7.4265e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 47/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.6134e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.9968e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 48/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.6088e-04 - root_mean_squared_error: 0.0257 - val_loss: 8.3253e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 49/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.6180e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.3281e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 50/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.5932e-04 - root_mean_squared_error: 0.0257 - val_loss: 6.6312e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 51/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5934e-04 - root_mean_squared_error: 0.0257 - val_loss: 5.9704e-05 - val_root_mean_squared_error: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5825e-04 - root_mean_squared_error: 0.0257 - val_loss: 7.0845e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 53/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5649e-04 - root_mean_squared_error: 0.0256 - val_loss: 6.6607e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 54/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.5754e-04 - root_mean_squared_error: 0.0256 - val_loss: 6.1967e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 55/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5528e-04 - root_mean_squared_error: 0.0256 - val_loss: 5.9820e-05 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 56/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5527e-04 - root_mean_squared_error: 0.0256 - val_loss: 7.3192e-05 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 57/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5451e-04 - root_mean_squared_error: 0.0256 - val_loss: 6.3982e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 58/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.5476e-04 - root_mean_squared_error: 0.0256 - val_loss: 6.1070e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 59/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.5307e-04 - root_mean_squared_error: 0.0256 - val_loss: 6.0622e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 60/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5117e-04 - root_mean_squared_error: 0.0255 - val_loss: 6.9724e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 61/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.5283e-04 - root_mean_squared_error: 0.0256 - val_loss: 5.5404e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 62/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.5067e-04 - root_mean_squared_error: 0.0255 - val_loss: 6.6199e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 63/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5199e-04 - root_mean_squared_error: 0.0255 - val_loss: 5.8917e-05 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 64/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.5090e-04 - root_mean_squared_error: 0.0255 - val_loss: 5.6407e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 65/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.4977e-04 - root_mean_squared_error: 0.0255 - val_loss: 6.5531e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 66/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.5002e-04 - root_mean_squared_error: 0.0255 - val_loss: 6.6636e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 67/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.5069e-04 - root_mean_squared_error: 0.0255 - val_loss: 5.9886e-05 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 68/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.5067e-04 - root_mean_squared_error: 0.0255 - val_loss: 6.8379e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 69/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4812e-04 - root_mean_squared_error: 0.0255 - val_loss: 6.0051e-05 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 70/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.4679e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.6555e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 71/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4599e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.6340e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 72/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4752e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.6524e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 73/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4661e-04 - root_mean_squared_error: 0.0254 - val_loss: 8.2769e-05 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 74/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4622e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.3153e-05 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 75/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4700e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.5426e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 76/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4447e-04 - root_mean_squared_error: 0.0254 - val_loss: 6.1328e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 77/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4636e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.0585e-05 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 78/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4617e-04 - root_mean_squared_error: 0.0254 - val_loss: 7.2195e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 79/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.4466e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.6403e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 80/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4431e-04 - root_mean_squared_error: 0.0254 - val_loss: 6.8576e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 81/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4447e-04 - root_mean_squared_error: 0.0254 - val_loss: 6.0198e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 82/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4223e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.5235e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 83/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4399e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.1088e-05 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 84/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4304e-04 - root_mean_squared_error: 0.0254 - val_loss: 4.9645e-05 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 85/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4265e-04 - root_mean_squared_error: 0.0254 - val_loss: 5.4096e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 86/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4212e-04 - root_mean_squared_error: 0.0253 - val_loss: 4.9453e-05 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 87/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.4198e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.8040e-05 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 88/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4107e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.5854e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 89/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4022e-04 - root_mean_squared_error: 0.0253 - val_loss: 6.6301e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 90/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.4146e-04 - root_mean_squared_error: 0.0253 - val_loss: 6.2282e-05 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 91/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.4122e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.5532e-05 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 92/100\n",
      "1806/1806 [==============================] - 135s 75ms/step - loss: 6.3929e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.5391e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 93/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.3983e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.4944e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 94/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.3905e-04 - root_mean_squared_error: 0.0253 - val_loss: 4.6044e-05 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 95/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.3773e-04 - root_mean_squared_error: 0.0253 - val_loss: 6.6823e-05 - val_root_mean_squared_error: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "1806/1806 [==============================] - 133s 73ms/step - loss: 6.3838e-04 - root_mean_squared_error: 0.0253 - val_loss: 5.5046e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 97/100\n",
      "1806/1806 [==============================] - 134s 74ms/step - loss: 6.3730e-04 - root_mean_squared_error: 0.0252 - val_loss: 5.1404e-05 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 98/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.3668e-04 - root_mean_squared_error: 0.0252 - val_loss: 5.3367e-05 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 99/100\n",
      "1806/1806 [==============================] - 133s 74ms/step - loss: 6.3396e-04 - root_mean_squared_error: 0.0252 - val_loss: 5.0417e-05 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 100/100\n",
      "1806/1806 [==============================] - 133s 73ms/step - loss: 6.3543e-04 - root_mean_squared_error: 0.0252 - val_loss: 4.9583e-05 - val_root_mean_squared_error: 0.0070\n",
      "1506/1506 [==============================] - 102s 67ms/step\n",
      "1506/1506 [==============================] - 101s 67ms/step\n",
      "Model::::::::::::::::::::::::::::::: 0\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 1\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 2\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 3\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 4\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 5\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 6\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 7\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 8\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 9\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 10\n",
      "No. of repeatitions completed: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 11\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 12\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 13\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 14\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 15\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 16\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 17\n",
      "No. of repeatitions completed: 0\n",
      "[04:50:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 1\n",
      "[04:50:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 2\n",
      "[04:51:12] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 3\n",
      "[04:51:35] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 4\n",
      "[04:51:58] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 5\n",
      "[04:52:20] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 6\n",
      "[04:52:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 7\n",
      "[04:53:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 8\n",
      "[04:53:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of repeatitions completed: 9\n",
      "[04:53:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 10\n",
      "[04:54:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 11\n",
      "[04:54:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 12\n",
      "[04:54:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 13\n",
      "[04:55:22] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 14\n",
      "[04:55:45] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 15\n",
      "[04:56:07] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 16\n",
      "[04:56:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 17\n",
      "[04:56:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 18\n",
      "[04:57:15] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 19\n",
      "[04:57:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Model::::::::::::::::::::::::::::::: 18\n",
      "No. of repeatitions completed: 0\n",
      "[04:58:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 1\n",
      "[04:58:32] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 2\n",
      "[04:58:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 3\n",
      "[04:59:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 4\n",
      "[04:59:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 5\n",
      "[04:59:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 6\n",
      "[05:00:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 7\n",
      "[05:00:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 8\n",
      "[05:01:05] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 9\n",
      "[05:01:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of repeatitions completed: 10\n",
      "[05:01:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 11\n",
      "[05:02:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 12\n",
      "[05:02:32] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 13\n",
      "[05:02:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 14\n",
      "[05:03:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 15\n",
      "[05:03:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 16\n",
      "[05:04:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 17\n",
      "[05:04:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 18\n",
      "[05:04:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 19\n",
      "[05:05:05] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Model::::::::::::::::::::::::::::::: 19\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 20\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n"
     ]
    }
   ],
   "source": [
    "#Read the Time Series Dataset\n",
    "Timeseries_Data=pd.read_csv('AQI.csv',header=None)\n",
    "linear_Data=pd.read_csv('ARIMA.csv',header=None)\n",
    "Residual_Data=pd.DataFrame(np.zeros((Timeseries_Data.shape[0],1)))\n",
    "LagLength=24\n",
    "h=1\n",
    "NumberOfRepeatitions=20\n",
    "lt=Timeseries_Data.shape[0]\n",
    "lenTrain=int(round(lt*0.6))\n",
    "lenValidation=int(round(lt*0.2))\n",
    "lenTest=int(lt-lenTrain-lenValidation)\n",
    "#Compute the Residual Series\n",
    "for i in range(lt):\n",
    "    Residual_Data.iloc[i,0]=Timeseries_Data.iloc[i,0]-linear_Data.iloc[i,0]\n",
    "# NORMALIZE THE DATA\n",
    "normalizedData=minmaxNorm(Residual_Data,lenTrain+lenValidation);\n",
    "# Transform the Time Series into Patterns Using Sliding Window\n",
    "X, y = get_Patterns(normalizedData, LagLength, h)\n",
    "CNNFeatures=Find_Features_CNN(X,y,lenValidation,lenTest)\n",
    "ConvLSTMFeatures=Find_Features_ConvLSTM(X,y,lenValidation,lenTest)\n",
    "BiLSTMFeatures=Find_Features_BiLSTM(X,y,lenValidation,lenTest)\n",
    "LSTMFeatures=Find_Features_LSTM(X,y,lenValidation,lenTest)\n",
    "X=np.hstack((CNNFeatures,LSTMFeatures,BiLSTMFeatures,ConvLSTMFeatures))\n",
    "#X = SelectKBest(score_func=f_regression, k=24).fit_transform(X, y)\n",
    "pca = PCA(n_components=9)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "#ICA = FastICA(n_components=6)\n",
    "#X=ICA.fit_transform(X)\n",
    "\n",
    "MeanAccuracyT=pd.DataFrame()\n",
    "StdAccuracyT=pd.DataFrame()\n",
    "for j in range(0,21,1):\n",
    "    print('Model:::::::::::::::::::::::::::::::',j)\n",
    "    if j==0:         \n",
    "        model=LinearRegression()\n",
    "        name='1.LinearRegression'\n",
    "    elif j==1:\n",
    "        model=Lasso()\n",
    "        name='2.Lasso'\n",
    "    elif j==2:\n",
    "        model=Ridge()\n",
    "        name='3.Ridge'\n",
    "    elif j==3:\n",
    "        model=ElasticNet()\n",
    "        name='4.ElasticNet'\n",
    "    elif j==4:\n",
    "        model=HuberRegressor()\n",
    "        name='5.HuberRegressor'\n",
    "    elif j==5:\n",
    "        model=SGDRegressor()\n",
    "        name='6.SGDRegressor'\n",
    "    elif j==6:\n",
    "        model=TweedieRegressor()\n",
    "        name='7.TweedieRegressor'\n",
    "    elif j==7:\n",
    "        model=AdaBoostRegressor()\n",
    "        name='8.AdaBoostRegressor'\n",
    "    elif j==8:\n",
    "        model=RandomForestRegressor()\n",
    "        name='9.RandomForestRegressor'\n",
    "    elif j==9:\n",
    "        model=GradientBoostingRegressor()\n",
    "        name='10.GradientBoostingRegressor'\n",
    "    elif j==10:\n",
    "        model=LinearSVR()\n",
    "        name='11.LinearSVR'\n",
    "    elif j==11:\n",
    "        model=MLPRegressor()\n",
    "        name='12.MLP'\n",
    "    elif j==12:\n",
    "        model=SVR()\n",
    "        name='13.SVR'\n",
    "    elif j==13:\n",
    "        model=ExtraTreesRegressor()\n",
    "        name='14.ExtraTreesRegressor'\n",
    "    elif j==14:\n",
    "        model=BaggingRegressor()\n",
    "        name='15.BaggingRegressor'\n",
    "    elif j==15:\n",
    "        model=DecisionTreeRegressor()\n",
    "        name='16.DecisionTreeRegressor'\n",
    "    elif j==16:\n",
    "        model=KNeighborsRegressor()\n",
    "        name='17.KNeighborsRegressor'\n",
    "    elif j==17:\n",
    "        model=xgb.XGBRegressor(silent=True)\n",
    "        name='18.XGB'\n",
    "    elif j==18:\n",
    "        model=StackingRegressor(regressors=[Lasso(),TweedieRegressor()],meta_regressor=xgb.XGBRegressor(silent=True))\n",
    "        name='19.Lasso_Tweedi_xgb'\n",
    "    elif j==19:\n",
    "        model=StackingRegressor(regressors=[Lasso(),TweedieRegressor()],meta_regressor=LinearSVR())\n",
    "        name='20.Lasso_Tweedi_LinearSVR'\n",
    "    elif j==20:\n",
    "        model=StackingRegressor(regressors=[Lasso(),TweedieRegressor()],meta_regressor=Lasso())\n",
    "        name='21.Lasso_Tweedi_Lasso'\n",
    "    elif j==21:\n",
    "        name='22.LSTM'\n",
    "    elif j==22:\n",
    "        name='23.CNN'\n",
    "    elif j==23:\n",
    "        name='24.DMLP' \n",
    "    elif j==24:\n",
    "        name='25.GRU'\n",
    "    else:\n",
    "        print('Completed.....................')\n",
    "\n",
    "    file1='./'+str(name)+\"_Accuracy.xlsx\"\n",
    "    file2='./'+str(name)+\"_Forecasts.xlsx\"\n",
    "    Forecasts=pd.DataFrame()\n",
    "    Accuracy=pd.DataFrame()\n",
    "    for i in range(NumberOfRepeatitions):\n",
    "        print('No. of repeatitions completed:',i)\n",
    "        if j<=20:\n",
    "            ynorm1=Find_Fitness(X,y,lenValidation,lenTest,model)\n",
    "        elif j==21:\n",
    "            ynorm1=Find_Fitness_LSTM(X,y,lenValidation,lenTest)\n",
    "        elif j==22:\n",
    "            ynorm1=Find_Fitness_CNN(X,y,lenValidation,lenTest)\n",
    "        elif j==23:\n",
    "            ynorm1=Find_Fitness_DMLP(X,y,lenValidation,lenTest)\n",
    "        else:\n",
    "            ynorm1=Find_Fitness_GRU(X,y,lenValidation,lenTest)\n",
    "        ynorm=pd.DataFrame(normalizedData.iloc[0:LagLength,0])\n",
    "        ynorm=ynorm.append(ynorm1,ignore_index = True)\n",
    "        yhat2=minmaxDeNorm(Residual_Data, ynorm, lenTrain+lenValidation)\n",
    "        yhat=pd.DataFrame(np.zeros((Timeseries_Data.shape[0],1)))\n",
    "        for ii in range(lt):\n",
    "            yhat.iloc[ii,0]=yhat2.iloc[ii,0]+linear_Data.iloc[ii,0]\n",
    "        Accuracy.loc[i,0],Accuracy.loc[i,1]=findRMSE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Accuracy.loc[i,2],Accuracy.loc[i,3]=findSMAPE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Accuracy.loc[i,4],Accuracy.loc[i,5]=findMAE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Accuracy.loc[i,6],Accuracy.loc[i,7]=findMASE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Forecasts=Forecasts.append(yhat.T,ignore_index = True)\n",
    "    Accuracy.to_excel(file1,sheet_name='Accuracy',index=False)\n",
    "    Forecasts.T.to_excel(file2,sheet_name='Forecasts',index=False)\n",
    "    MeanAccuracy=pd.DataFrame(np.mean(Accuracy))    \n",
    "    MeanAccuracyT=MeanAccuracyT.append(MeanAccuracy.T, ignore_index = True)\n",
    "    StdAccuracy=pd.DataFrame(np.std(Accuracy))    \n",
    "    StdAccuracyT=StdAccuracyT.append(StdAccuracy.T, ignore_index = True)\n",
    "    del Accuracy\n",
    "    del Forecasts\n",
    "    del MeanAccuracy\n",
    "    del StdAccuracy\n",
    "MeanAccuracyT.to_excel('All_Model_Mean_Accuracy.xlsx',sheet_name='All_Model_Accuracy',index=False)\n",
    "del MeanAccuracyT\n",
    "StdAccuracyT.to_excel('All_Model_Stdev_Accuracy.xlsx',sheet_name='All_Model_Stdev_Accuracy',index=False)\n",
    "del StdAccuracyT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88067358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model::::::::::::::::::::::::::::::: 0\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 1\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 2\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 3\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 4\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 5\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 6\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 7\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 8\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 9\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 10\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 11\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 12\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 13\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 14\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 15\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 16\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 17\n",
      "No. of repeatitions completed: 0\n",
      "[12:56:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 1\n",
      "[12:56:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 2\n",
      "[12:57:15] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 3\n",
      "[12:57:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 4\n",
      "[12:58:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 5\n",
      "[12:58:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 6\n",
      "[12:58:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 7\n",
      "[12:59:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 8\n",
      "[12:59:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 9\n",
      "[13:00:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 10\n",
      "[13:00:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 11\n",
      "[13:00:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of repeatitions completed: 12\n",
      "[13:01:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 13\n",
      "[13:01:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 14\n",
      "[13:02:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 15\n",
      "[13:02:25] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 16\n",
      "[13:02:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 17\n",
      "[13:03:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 18\n",
      "[13:03:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 19\n",
      "[13:04:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Model::::::::::::::::::::::::::::::: 18\n",
      "No. of repeatitions completed: 0\n",
      "[13:04:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 1\n",
      "[13:04:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 2\n",
      "[13:05:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 3\n",
      "[13:05:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 4\n",
      "[13:06:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 5\n",
      "[13:06:22] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 6\n",
      "[13:06:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 7\n",
      "[13:07:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 8\n",
      "[13:07:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 9\n",
      "[13:07:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 10\n",
      "[13:08:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 11\n",
      "[13:08:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 12\n",
      "[13:08:52] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of repeatitions completed: 13\n",
      "[13:09:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 14\n",
      "[13:09:35] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 15\n",
      "[13:09:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 16\n",
      "[13:10:18] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 17\n",
      "[13:10:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 18\n",
      "[13:11:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "No. of repeatitions completed: 19\n",
      "[13:11:22] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Model::::::::::::::::::::::::::::::: 19\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n",
      "Model::::::::::::::::::::::::::::::: 20\n",
      "No. of repeatitions completed: 0\n",
      "No. of repeatitions completed: 1\n",
      "No. of repeatitions completed: 2\n",
      "No. of repeatitions completed: 3\n",
      "No. of repeatitions completed: 4\n",
      "No. of repeatitions completed: 5\n",
      "No. of repeatitions completed: 6\n",
      "No. of repeatitions completed: 7\n",
      "No. of repeatitions completed: 8\n",
      "No. of repeatitions completed: 9\n",
      "No. of repeatitions completed: 10\n",
      "No. of repeatitions completed: 11\n",
      "No. of repeatitions completed: 12\n",
      "No. of repeatitions completed: 13\n",
      "No. of repeatitions completed: 14\n",
      "No. of repeatitions completed: 15\n",
      "No. of repeatitions completed: 16\n",
      "No. of repeatitions completed: 17\n",
      "No. of repeatitions completed: 18\n",
      "No. of repeatitions completed: 19\n"
     ]
    }
   ],
   "source": [
    "X=np.hstack((CNNFeatures,LSTMFeatures,BiLSTMFeatures,ConvLSTMFeatures))\n",
    "#X = SelectKBest(score_func=f_regression, k=24).fit_transform(X, y)\n",
    "ICA = FastICA(n_components=24)\n",
    "X=ICA.fit_transform(X)\n",
    "MeanAccuracyT=pd.DataFrame()\n",
    "StdAccuracyT=pd.DataFrame()\n",
    "for j in range(0,21,1):\n",
    "    print('Model:::::::::::::::::::::::::::::::',j)\n",
    "    if j==0:         \n",
    "        model=LinearRegression()\n",
    "        name='1.LinearRegression'\n",
    "    elif j==1:\n",
    "        model=Lasso()\n",
    "        name='2.Lasso'\n",
    "    elif j==2:\n",
    "        model=Ridge()\n",
    "        name='3.Ridge'\n",
    "    elif j==3:\n",
    "        model=ElasticNet()\n",
    "        name='4.ElasticNet'\n",
    "    elif j==4:\n",
    "        model=HuberRegressor()\n",
    "        name='5.HuberRegressor'\n",
    "    elif j==5:\n",
    "        model=SGDRegressor()\n",
    "        name='6.SGDRegressor'\n",
    "    elif j==6:\n",
    "        model=TweedieRegressor()\n",
    "        name='7.TweedieRegressor'\n",
    "    elif j==7:\n",
    "        model=AdaBoostRegressor()\n",
    "        name='8.AdaBoostRegressor'\n",
    "    elif j==8:\n",
    "        model=RandomForestRegressor()\n",
    "        name='9.RandomForestRegressor'\n",
    "    elif j==9:\n",
    "        model=GradientBoostingRegressor()\n",
    "        name='10.GradientBoostingRegressor'\n",
    "    elif j==10:\n",
    "        model=LinearSVR()\n",
    "        name='11.LinearSVR'\n",
    "    elif j==11:\n",
    "        model=MLPRegressor()\n",
    "        name='12.MLP'\n",
    "    elif j==12:\n",
    "        model=SVR()\n",
    "        name='13.SVR'\n",
    "    elif j==13:\n",
    "        model=ExtraTreesRegressor()\n",
    "        name='14.ExtraTreesRegressor'\n",
    "    elif j==14:\n",
    "        model=BaggingRegressor()\n",
    "        name='15.BaggingRegressor'\n",
    "    elif j==15:\n",
    "        model=DecisionTreeRegressor()\n",
    "        name='16.DecisionTreeRegressor'\n",
    "    elif j==16:\n",
    "        model=KNeighborsRegressor()\n",
    "        name='17.KNeighborsRegressor'\n",
    "    elif j==17:\n",
    "        model=xgb.XGBRegressor(silent=True)\n",
    "        name='18.XGB'\n",
    "    elif j==18:\n",
    "        model=StackingRegressor(regressors=[Lasso(),TweedieRegressor()],meta_regressor=xgb.XGBRegressor(silent=True))\n",
    "        name='19.Lasso_Tweedi_xgb'\n",
    "    elif j==19:\n",
    "        model=StackingRegressor(regressors=[Lasso(),TweedieRegressor()],meta_regressor=LinearSVR())\n",
    "        name='20.Lasso_Tweedi_LinearSVR'\n",
    "    elif j==20:\n",
    "        model=StackingRegressor(regressors=[Lasso(),TweedieRegressor()],meta_regressor=Lasso())\n",
    "        name='21.Lasso_Tweedi_Lasso'\n",
    "    elif j==21:\n",
    "        name='22.LSTM'\n",
    "    elif j==22:\n",
    "        name='23.CNN'\n",
    "    elif j==23:\n",
    "        name='24.DMLP' \n",
    "    elif j==24:\n",
    "        name='25.GRU'\n",
    "    else:\n",
    "        print('Completed.....................')\n",
    "\n",
    "    file1='./'+str(name)+\"_Accuracy.xlsx\"\n",
    "    file2='./'+str(name)+\"_Forecasts.xlsx\"\n",
    "    Forecasts=pd.DataFrame()\n",
    "    Accuracy=pd.DataFrame()\n",
    "    for i in range(NumberOfRepeatitions):\n",
    "        print('No. of repeatitions completed:',i)\n",
    "        if j<=20:\n",
    "            ynorm1=Find_Fitness(X,y,lenValidation,lenTest,model)\n",
    "        elif j==21:\n",
    "            ynorm1=Find_Fitness_LSTM(X,y,lenValidation,lenTest)\n",
    "        elif j==22:\n",
    "            ynorm1=Find_Fitness_CNN(X,y,lenValidation,lenTest)\n",
    "        elif j==23:\n",
    "            ynorm1=Find_Fitness_DMLP(X,y,lenValidation,lenTest)\n",
    "        else:\n",
    "            ynorm1=Find_Fitness_GRU(X,y,lenValidation,lenTest)\n",
    "        ynorm=pd.DataFrame(normalizedData.iloc[0:LagLength,0])\n",
    "        ynorm=ynorm.append(ynorm1,ignore_index = True)\n",
    "        yhat2=minmaxDeNorm(Residual_Data, ynorm, lenTrain+lenValidation)\n",
    "        yhat=pd.DataFrame(np.zeros((Timeseries_Data.shape[0],1)))\n",
    "        for ii in range(lt):\n",
    "            yhat.iloc[ii,0]=yhat2.iloc[ii,0]+linear_Data.iloc[ii,0]\n",
    "        Accuracy.loc[i,0],Accuracy.loc[i,1]=findRMSE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Accuracy.loc[i,2],Accuracy.loc[i,3]=findSMAPE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Accuracy.loc[i,4],Accuracy.loc[i,5]=findMAE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Accuracy.loc[i,6],Accuracy.loc[i,7]=findMASE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "        Forecasts=Forecasts.append(yhat.T,ignore_index = True)\n",
    "    Accuracy.to_excel(file1,sheet_name='Accuracy',index=False)\n",
    "    Forecasts.T.to_excel(file2,sheet_name='Forecasts',index=False)\n",
    "    MeanAccuracy=pd.DataFrame(np.mean(Accuracy))    \n",
    "    MeanAccuracyT=MeanAccuracyT.append(MeanAccuracy.T, ignore_index = True)\n",
    "    StdAccuracy=pd.DataFrame(np.std(Accuracy))    \n",
    "    StdAccuracyT=StdAccuracyT.append(StdAccuracy.T, ignore_index = True)\n",
    "    del Accuracy\n",
    "    del Forecasts\n",
    "    del MeanAccuracy\n",
    "    del StdAccuracy\n",
    "MeanAccuracyT.to_excel('All_Model_Mean_Accuracy.xlsx',sheet_name='All_Model_Accuracy',index=False)\n",
    "del MeanAccuracyT\n",
    "StdAccuracyT.to_excel('All_Model_Stdev_Accuracy.xlsx',sheet_name='All_Model_Stdev_Accuracy',index=False)\n",
    "del StdAccuracyT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
